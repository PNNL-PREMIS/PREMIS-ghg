---
title: "Soil respiration: gap-filling and annual flux estimation"
author: "Ben Bond-Lamberty"
date: "28 October 2019"
output: html_document
---

## Introduction

* Noodling

```{r setup, include=FALSE}
library(drake)
knitr::opts_chunk$set(echo = FALSE)
library(readr)
library(dplyr)
library(tidyr)
library(ggplot2)
library(lubridate)
library(kableExtra)
library(lattice)
library(cowplot)  # 0.9.4
theme_set(theme_bw())
#theme_set(theme_cowplot())

N_HISTOGRAM_BINS <- 20
START_DATE <- "2017-10-01"
END_DATE <- "2099-08-01"

readd("con_licor_data") %>% 
  filter(Timestamp >= START_DATE, Timestamp < END_DATE) %>% 
  arrange(Timestamp, Port) ->
  cld

```

Data limits are `r START_DATE` to `r END_DATE`.


```{r filtering}
cld %>% 
  filter(R2 > 0.75, !is.na(Flux)) %>%  # probably a chamber closing problem otherwise
  group_by(week(Timestamp)) %>% 
  mutate(mad = abs(Flux - median(Flux,  na.rm = TRUE)) / mad(Flux, na.rm = TRUE)) %>% 
  ungroup() %>% 
  filter(mad <= 4) %>% 
  ungroup() ->
  cld_clean
removed_cld <- nrow(cld) - nrow(cld_clean)
```

Continuous data: `r nrow (cld)` observations; `r removed_cld` (`r round(removed_cld / nrow(cld) * 100, 0)`%) removed because of chamber closure or other problems. Final data is `r nrow(cld_clean)` observations.

Have data for `r length(unique(yday(cld_clean$Timestamp)))` unique days of the year.

```{r missing-dates}
# Insert missing dates
cld_clean$Timestamp <- as.POSIXct(round(cld_clean$Timestamp, "hour"))
mints <- min(cld_clean$Timestamp)
maxts <- max(cld_clean$Timestamp)

cld_clean %>% 
  group_by(Timestamp, Port) %>%
  summarise(Flux = mean(Flux, na.rm = TRUE))->
  cld_clean_avg

expand.grid(Port = 1:8,
            Timestamp = seq(mints, maxts, by = "hour")) %>% 
  as_tibble() %>%  
  left_join(cld_clean_avg, by = c("Port", "Timestamp")) %>% 
  mutate(Year = year(Timestamp), Month = month(Timestamp),
         Yday = yday(Timestamp), Hour = hour(Timestamp)) %>% 
  select(Timestamp, Year, Month, Yday, Hour, Port, Flux) ->
  cld_clean_hourly
```

After missing-date insertion, have data for `r length(unique(cld_clean_hourly$Yday))` unique days of the year.

## Distribution and variability

```{r continuous-plot, fig.height=8}
cld_clean_hourly %>% 
  mutate(Year = as.factor(Year)) %>% 
  ggplot(aes(yday(Timestamp), Flux, color = Year)) + 
  geom_line(alpha = 0.75, na.rm = TRUE) + facet_grid(Port ~ .) +
  ggtitle("A. Continuous data")
```

```{r distributions}
ggplot(cld_clean, aes(x = Flux, color = factor(Port))) + geom_density() +
  ggtitle("B. Distribution")
```


```{r continuous-collar-cv}
cld_clean_hourly %>% 
  mutate(Year = as.factor(year(Timestamp)),
         Hour = hour(Timestamp)) %>% 
  group_by(Year, Yday, Hour) %>% 
  summarise(Flux_cv = sd(Flux) / mean(Flux)) %>% 
  ungroup() ->
  cld_cv

cld_cv %>% 
  ggplot(aes(Yday, Flux_cv, color = Year)) + 
  geom_point(alpha = 0.5, na.rm = TRUE) +
  ggtitle("C. Collar-to-collar CV")

cld_clean_hourly %>% 
  mutate(Month = month(Timestamp),
         Hour = hour(Timestamp)) %>% 
  group_by(Month, Hour) %>% 
  summarise(Flux_cv = sd(Flux, na.rm = TRUE) / mean(Flux, na.rm = TRUE)) %>% 
  ungroup() %>% 
  ggplot(aes(Hour, Flux_cv, color = Month, group = Month)) + 
  geom_line() +
  ggtitle("D. Collar-to-collar CV by month")
```

## Gapfilling

>A second challenge is posed by a large component of random error. It originates from intrinsic fine-scale processes such as microbial metabolic pathways, gas diffusion, or microbial population dynamics and, to a smaller extent, from instrumentation (Lavoie et al., 2015; PeÌrez-Priego et al., 2015) (see section 2.2 for terminology). Random error is usually assumed to be normally distributed, however, violation of this assumption poses problems for analysis and aggregation across space and time. A first problem is the increasing variance with increasing flux, which violates the assumption of homoscedasticity of variance, which is the base of many statistical tests. A second problem is the occurrence of strong tails, i.e., higher probability of large absolute errors (Savage et al., 2008; Cueva et al., 2015; Lavoie et al., 2015) compared to the normal assumption. This is often associated with hot spots and hot moments, i.e., locations or times where large fluxes occur at a small scale (Leon et al., 2014; Vargas et al., 2018). To overcome these problems, Savage et al. (2008) proposed using the Laplace distribution. If this proposal is applicable depends on how the data will be used. For instance, model-data integration studies can use the Laplace assumption by using a cost-function that is based on the median absolute deviation rather than the squared difference (Richardson et al., 2006). However, other statistical methods still rely on the normal assumption. For instance, using mixed effects models (Pinheiro and Bates, 2000; Zuur et al., 2009) in aggregating measurements across several chambers requires the normal assumption for a random effect to represent grouping in the data.

>A simple method to estimate the error terms is daily differencing, excluding days with and after rain events (Savage et al., 2008). The daily differencing method assumes that records 24 hours apart represent similar environmental conditions and hence differences in the observed flux can be used to estimate the random error...

>An alternative method is the Lookup-Table approach (LUT). It is commonly used in the marginal distribution sampling method (Reichstein et al., 2005)...

>A third alternative is modeling the base flux by its relationship with ancillary observations, such as temperature. We tried modeling the CO2 efflux temperature relationship with varying basal respiration (Gomez-Casanovas et al., 2013; Reichstein et al., 2005)...

>Contrary to the short term aggregation, distribution of annually aggregated fluxes of each chamber did not differ between the two approaches (Fig. 5). 

https://www.geosci-instrum-method-data-syst-discuss.net/gi-2019-10/

Also Gomez-Casanovas et al. (2013), http://dx.doi.org/10.1111/gcb.12127

If we aggregate chamber to annual fluxes and then compute a mean, versus compute a mean and then aggregate to annual flux, how does that affect things? See Wutzler et al. link above:

>The "space first" alternative yielded lower uncertainty estimates because it wrongly assumed true replicates when in reality there are only pseudo-spatial replicates (Fig. 6), i.e. locations did not change between successive measurements.

```{r gapfill}
# Compute s.d. of the log values, by port and month
cld_clean_hourly %>% 
  filter(Flux > 0) %>% 
  group_by(Month, Port) %>% 
  summarise(Flux_logsd = sd(log(Flux), na.rm = TRUE),
            Flux_sd = sd(Flux, na.rm = TRUE)) ->
  cld_sd

# What's the difference if we use rnorm versus rlnorm (following XXX)

cld_clean_hourly %>% 
  left_join(cld_sd, by = c("Month", "Port")) %>% 
  arrange(Timestamp) %>% 
  group_by(Port) %>% 
  mutate(Flux_approx = approx(Timestamp, Flux, xout = Timestamp, rule = 2)$y) %>% 
  ungroup() ->
  cld_clean_gapfill

cld_clean_gapfill %>% 
  mutate(Type = "rnorm",
         Flux_approx_noise = if_else(is.na(Flux),
                                     abs(rnorm(n(), Flux_approx, Flux_sd)),
                                     Flux)) ->
  cld_clean_gapfill_noise

cld_clean_gapfill %>% 
  mutate(Type = "rlnorm",
         Flux_approx_noise = if_else(is.na(Flux),
                                     rlnorm(n(), log(Flux_approx), Flux_logsd),
                                     Flux)) ->
  cld_clean_gapfill_lognoise


cld_clean_gapfill_all <- bind_rows(cld_clean_gapfill_noise, cld_clean_gapfill_lognoise)

cld_clean_gapfill_all %>% 
  filter(is.na(Flux)) %>% 
  spread(Type, Flux_approx_noise) %>% 
  ggplot(aes(rnorm, rlnorm)) + geom_point(alpha = 0.5) + geom_abline(color = "blue") + 
  facet_wrap(~Port, scales = "free") ->
  p
print(p)

# Compute annual mean flux for each port and gapfill type
cld_clean_gapfill_all %>% 
  group_by(Type, Port, Yday) %>% 
  summarise(Flux_approx_noise = mean(Flux_approx_noise, na.rm = TRUE)) %>% 
  summarise(Flux_approx_noise = mean(Flux_approx_noise, na.rm = TRUE)) %>% 
  group_by(Type) %>% 
  summarise_at("Flux_approx_noise", tibble::lst(mean, sd))

cld_clean_gapfill_all %>% 
  filter(Port == 2) %>% 
  ggplot(aes(Timestamp, Flux_approx_noise, color = Type)) +
  geom_point() +
  facet_grid(Port ~ .) ->
  p
print(p)
```



As we changing sampling frequency, how does our estimate of Rs_annual change?

```{r bootstrap, cache=TRUE}
compute_frac_mean <- function(frac, df) {
  mean(df$Flux_approx_noise[sample.int(nrow(df), nrow(df) * frac)])
}

set.seed(12345)
N_MC <- 1000
cld_clean_gapfill_noise %>% 
  group_by(Port) %>% 
  summarise(meanflux = mean(Flux_approx, na.rm = TRUE)) ->
  meanflux

results <- list()
for(p in unique(cld_clean_gapfill_noise$Port)) {
  x <- filter(cld_clean_gapfill_noise, Port == p, !is.na(Flux_approx_noise))
  results[[p]] <- tibble(Port = p,
                         frac = rep(c(seq(0.001, 0.01, by = 0.002), 
                                      seq(0.01, 1, by = 0.075), 
                                      1.0), times = N_MC),
                         flux = sapply(frac, compute_frac_mean, x))
}

bind_rows(results) %>% 
  left_join(meanflux, by = "Port") %>% 
  # these are hourly data, so a fraction of 1 means ~730 times per month
  mutate(N_per_month = 365.25 * 24 / 12 * frac,
         flux_error = (flux - meanflux) / meanflux) %>% 
  group_by(Port, N_per_month, frac) %>% 
  summarise(n = n(), 
            flux_mean = mean(flux), 
            flux_sd = sd(flux),
            flux_error_mean = mean(flux_error),
            flux_error_sd = sd(flux_error),
            flux_error_95lwr = quantile(flux_error, 0.025),
            flux_error_95upr = quantile(flux_error, 0.975)) ->
  y

ggplot(y, aes(N_per_month, flux_error_mean)) + 
  geom_line() + 
  geom_ribbon(aes(ymin = flux_error_95lwr, 
                  ymax = flux_error_95upr), alpha = 0.5) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  scale_x_continuous(breaks = c(1, 4, 10, 30, 720)) +
  coord_trans(x = "log10") + 
  facet_wrap(~Port)
```



## Session

```{r, echo=FALSE}
sessionInfo()
```
